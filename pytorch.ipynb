{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    # TODO:define model\n",
    "    # initialize the model\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5, padding = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2))\n",
    "        )\n",
    "        \n",
    "        self.connect = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.layer(x)\n",
    "        y = y.view(-1, self.num_flat_features(y))\n",
    "        y = self.connect(y)\n",
    "        return y\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for key in size:\n",
    "            num_features *= key\n",
    "        return num_features\n",
    "\n",
    "    \n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=.1, momentum=0.9)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train and evaluate\n",
    "loss_list = []\n",
    "train_auc_list = []\n",
    "auc_list = []\n",
    "def train(model, optimizer, criterion, train_loader, device, epoch, loss_list, train_auc_list):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        # TODO:forward + backward + optimize      \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print('Epoch {} training loss {}, training accuracy {}'.format(epoch,running_loss/len(train_loader), 100*correct/total))\n",
    "    loss_list.append(running_loss/len(train_loader))\n",
    "    train_auc_list.append(100*correct/total)\n",
    "        \n",
    "\n",
    "        \n",
    "def test(model, criterion, test_loader, device, epoch, auc_list):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(test_loader):\n",
    "            output = model(images)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print('Epoch {} testing accuracy:{}'.format(epoch, 100*correct/total))\n",
    "    auc_list.append(100*correct/total)\n",
    "    \n",
    "    \n",
    "for epoch in trange(0, NUM_EPOCHS):\n",
    "    train(model, optimizer, criterion, train_loader, device, epoch, loss_list, train_auc_list)\n",
    "    test(model, criterion, test_loader, device, epoch, auc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    print('Epoch {} training accuracy {}, testing accuracy {}'.format(i+1, train_auc_list[i], auc_list[i]))\n",
    "\n",
    "'''\n",
    "Epoch 1 training accuracy 98.87653350830078, testing accuracy 98.26722717285156\n",
    "Epoch 2 training accuracy 98.82478332519531, testing accuracy 98.69791412353516\n",
    "Epoch 3 training accuracy 99.09688568115234, testing accuracy 98.56771087646484\n",
    "Epoch 4 training accuracy 99.03345489501953, testing accuracy 98.41746520996094\n",
    "Epoch 5 training accuracy 98.9967269897461, testing accuracy 98.0869369506836\n",
    "Epoch 6 training accuracy 98.96501159667969, testing accuracy 98.46754455566406\n",
    "Epoch 7 training accuracy 99.07351684570312, testing accuracy 98.0068130493164\n",
    "Epoch 8 training accuracy 99.07184600830078, testing accuracy 98.12700653076172\n",
    "Epoch 9 training accuracy 98.92327880859375, testing accuracy 97.96674346923828\n",
    "Epoch 10 training accuracy 98.90324401855469, testing accuracy 98.36738586425781\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
